<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习_KNN算法</title>
      <link href="/2022/10/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_KNN%E7%AE%97%E6%B3%95/"/>
      <url>/2022/10/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_KNN%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习-KNN算法"><a href="#机器学习-KNN算法" class="headerlink" title="机器学习_KNN算法"></a>机器学习_KNN算法</h1><h2 id="1、K-近邻算法"><a href="#1、K-近邻算法" class="headerlink" title="1、K-近邻算法"></a>1、K-近邻算法</h2><h3 id="1-1-定义-如果一个样本在特征空间中的k个最相似-即特征空间中最邻近-的样本中的大多数属于某一个类别，则该样本也属于这个类别。"><a href="#1-1-定义-如果一个样本在特征空间中的k个最相似-即特征空间中最邻近-的样本中的大多数属于某一个类别，则该样本也属于这个类别。" class="headerlink" title="1.1 定义:如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。"></a>1.1 定义:如果一个样本在特征空间中的<strong>k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别</strong>，则该样本也属于这个类别。</h3><h3 id="1-2-距离公式-两个样本的差距也叫距离可以通过如下公式计算（欧式公式）"><a href="#1-2-距离公式-两个样本的差距也叫距离可以通过如下公式计算（欧式公式）" class="headerlink" title="1.2 距离公式:两个样本的差距也叫距离可以通过如下公式计算（欧式公式）:"></a>1.2 距离公式:两个样本的差距也叫距离可以通过如下公式计算（欧式公式）:</h3><p>比如A(a1,b1,c1) B(a2,b2.c2)<br>$$<br>\sqrt[]{(a1-a2)^2+(b1-b2)^2+(c1-c2^2)}<br>$$</p><h3 id="也有很多其他公式可代表距离，不唯一"><a href="#也有很多其他公式可代表距离，不唯一" class="headerlink" title="也有很多其他公式可代表距离，不唯一"></a>也有很多其他公式可代表距离，不唯一</h3><h3 id="1-3-K-近邻算法API"><a href="#1-3-K-近邻算法API" class="headerlink" title="1.3 K-近邻算法API"></a>1.3 K-近邻算法API</h3><ul><li>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm=’auto’)<ul><li>n_neighbors：int,可选（默认= 5），k_neighbors查询默认使用的邻居数</li><li>algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)</li></ul></li></ul><h1 id="2-基于鸢尾花数据集的测试"><a href="#2-基于鸢尾花数据集的测试" class="headerlink" title="2.基于鸢尾花数据集的测试"></a>2.基于鸢尾花数据集的测试</h1><ol><li><p>获取数据</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure></li><li><p>划分数据集</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target,test_size=<span class="number">0.3</span>, random_state=<span class="number">6</span>)</span><br></pre></td></tr></table></figure><p>将鸢尾花数据分为训练数据和测试数据，测试数据用于之后的准确性判断</p></li><li><p>特征工程：标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test) <span class="comment"># 此处不能用fit_transform，x_test要和train做一样的操作，要用train的平均值，所以只transform就行</span></span><br></pre></td></tr></table></figure></li><li><p>KNN算法预估器</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><p>将K值设为3，即当前样本在特征空间中的3个最相似(特征空间中距离最近)的样本大多都属于同一类别，则该样本也属于同一类别</p></li><li><p>模型评估</p><ol><li><p>直接对比真实值和预测值</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y.predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict: \n&quot;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值: \n&quot;</span>,y_test==y_predict) </span><br></pre></td></tr></table></figure></li></ol></li></ol><p><img src="https://cdn.jsdelivr.net/gh/bibabu01/blog_img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E9%B8%A2%E5%B0%BE%E8%8A%B1_%E7%BB%93%E6%9E%9C.png"></p><ol start="2"><li><p>计算准确率</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = estimator.score(x_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为: \n&quot;</span>,score)</span><br></pre></td></tr></table></figure><img src="https://cdn.jsdelivr.net/gh/bibabu01/blog_img/机器学习_鸢尾花_准确率.png" style="zoom:200%;" /><ol start="3"><li>当test_size的值变化时，准确率也会变化。k值变化，准确率也会随之变化，k=3时，准确率=93.3%，k=4时，准确率=91%，k=5时，为95.6%，但不是线性变化。</li></ol></li></ol><h1 id="3-结果分析"><a href="#3-结果分析" class="headerlink" title="3.结果分析"></a>3.结果分析</h1><h2 id="k值大小对数据的影响"><a href="#k值大小对数据的影响" class="headerlink" title="k值大小对数据的影响:"></a>k值大小对数据的影响:</h2><p>k值取很小：容易受到异常点的影响</p><p>k值取很大：受到样本均衡的问题</p><p>性能问题:计算距离时，时间复杂度较高</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li><p>优点：</p><ul><li>简单，易于理解，易于实现，无需训练</li></ul></li><li><p>缺点：</p><ul><li>懒惰算法，对测试样本分类时的计算量大，内存开销大</li><li>必须指定K值，K值选择不当则分类精度不能保证</li></ul></li><li><p>使用场景：小数据场景，几千～几万样本，具体场景具体业务去测试</p></li></ul><p>ps：本文部分内容摘自GitBook</p>]]></content>
      
      
      <categories>
          
          <category> -机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习_算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客介绍</title>
      <link href="/2022/10/02/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
      <url>/2022/10/02/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="建站目的"><a href="#建站目的" class="headerlink" title="建站目的"></a>建站目的</h1><p>本站建立于2022年10月3日，笔者希望通过编写此博客督促自己的学习，同时记录生活中的美好和感悟</p><h1 id="博客分类"><a href="#博客分类" class="headerlink" title="博客分类"></a>博客分类</h1><p>博客大致会以记录学习为主，记录生活和感悟为辅。嗯…应该没了🥰</p>]]></content>
      
      
      <categories>
          
          <category> 本站介绍 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 介绍 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
